{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VvysYQVPOA-"
      },
      "source": [
        "# Deep Learning - MNIST Classification Using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjVajwVDiXNr"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./', train=True, download=True, transform=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnq6AicK3WI0"
      },
      "source": [
        "# Mounting Drive and Unzipping MNIST Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYJWVm0j05Os"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp /content/drive/MyDrive/Sanwal_MSCS_20004/MNIST_Data.zip ./\n",
        "\n",
        "!unzip MNIST_Data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daqyIytK4C60"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQcC0gppd1Hq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLiBfdtt4TOF"
      },
      "source": [
        "# Loading Dataset and Applying Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB7tAvy5WtIv"
      },
      "source": [
        "def loadDataset(data_dir,sizeTrain,sizeTest, batchSize,shuffle):\n",
        "\n",
        "  # data_dir = 'drive/MyDrive' #DOWNLOAD DATA FOR THIS\n",
        "\n",
        "  # TODO: Define transforms for the training data and testing data\n",
        "  train_transforms = transforms.Compose([transforms.Resize((sizeTrain,sizeTrain)),transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.0,),(0.5,)),\n",
        "                                        transforms. Grayscale ( num_output_channels=1 )])\n",
        "  \n",
        "#   train_transforms = transforms.Compose([transforms.Resize((sizeTrain,sizeTrain)),transforms.ToTensor(),\n",
        "#                                         transforms. Grayscale ( num_output_channels=1 )])\n",
        "\n",
        "  test_transforms = transforms.Compose([transforms.Resize((sizeTest,sizeTest)),transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.0,),(0.5,)),\n",
        "                                        transforms. Grayscale ( num_output_channels=1 )])\n",
        "  \n",
        "#   test_transforms = transforms.Compose([transforms.Resize((sizeTest,sizeTest)),transforms.ToTensor(),\n",
        "#                                         transforms. Grayscale ( num_output_channels=1 )])\n",
        "  # Loading dataset using ImageFolder method. Pass transforms in here.\n",
        "  \n",
        "  train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "  test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "  # Here train and test dataloader are created using train_data and test_data objects. Batch size tells how many images are \n",
        "  # loaded for one iteration. \n",
        "\n",
        "  train_data, validation_data = torch.utils.data.random_split(train_data, [50000,10000])\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=shuffle)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batchSize,shuffle= shuffle)\n",
        "  validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batchSize,shuffle= shuffle)\n",
        "  return train_loader, test_loader, validation_loader\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGWXV-m04cQD"
      },
      "source": [
        "# Creating Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu-5JYuPW12E"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,no_of_layers,input_dim,neurons_per_layer,dropout):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim,neurons_per_layer[0])\n",
        "        self.fc2 = nn.Linear(neurons_per_layer[0], neurons_per_layer[1])\n",
        "        self.dropout = nn.Dropout(dropout, inplace= True)\n",
        "        self.fc3 = nn.Linear(neurons_per_layer[1],neurons_per_layer[2])\n",
        "        # self.fc4 = nn.Linear(neurons_per_layer[2],neurons_per_layer[3])\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        # x = self.fc4(x)\n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwIVJWKN4l8Z"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LzGVEteXBGf"
      },
      "source": [
        "def train_model(data_size, model, train, validation, learning_rate, epochs, optimizer, loss_func, device):\n",
        "\n",
        "  train_loss = []\n",
        "  train_acc = []\n",
        "  validate_acc = []\n",
        "  validate_loss = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    total_tr_loss = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data1, target1) in enumerate(train):\n",
        "        data1, target1 = Variable(data1), Variable(target1)\n",
        "        data1, target1 = data1.to(device), target1.to(device)        \n",
        "        data1 = data1.view(-1, data_size)\n",
        "        optimizer.zero_grad()\n",
        "        net_out = model(data1)\n",
        "        loss = loss_func(net_out, target1)      \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target1.data).sum()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data1), len(train.dataset),\n",
        "                          100. * batch_idx / len(train), loss.item()))\n",
        "            total_tr_loss += loss.item()\n",
        "    train_acc.append(correct / len(train.dataset))\n",
        "    # train_loss.append(loss.item()\n",
        "    train_loss.append(total_tr_loss)\n",
        "\n",
        "    print('\\nTrain Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "                total_tr_loss, correct, len(train.dataset),\n",
        "                100. * correct / len(train.dataset)))\n",
        "\n",
        "    val_loss,val_accuracy = validate_model(model, validation, device, loss_func, data_size)\n",
        "    validate_acc.append(val_accuracy)\n",
        "    validate_loss.append(val_loss)\n",
        "    \n",
        "    torch.save(model.state_dict(), \"./weights.pth\")\n",
        "\n",
        "  return train_acc, train_loss, validate_acc, validate_loss\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSIRCZ6b4yZo"
      },
      "source": [
        "# Validate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR0x0gkjXJ4I"
      },
      "source": [
        "def validate_model(model,val_data,device,loss_func, data_size):\n",
        "\n",
        "# this code cell calculates accuracy of test data on the trained model.\n",
        "    validation_loss= 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_data:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            data = data.view(-1, data_size)\n",
        "            net_out = model(data)\n",
        "            # sum up batch loss\n",
        "            validation_loss += loss_func(net_out, target).item()\n",
        "\n",
        "            pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data).sum()\n",
        "\n",
        "        validation_loss /= len(val_data.dataset)\n",
        "        validation_accuracy = correct/len(val_data.dataset)\n",
        "        print('\\nValidation Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "                validation_loss, correct, len(val_data.dataset),\n",
        "                100. * correct / len(val_data.dataset)))\n",
        "        \n",
        "    return validation_loss, validation_accuracy\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWd9LZFJ42wl"
      },
      "source": [
        "# Plotting Train Accuracy and Loss, Validation Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGz14AT1XRQD"
      },
      "source": [
        "def plot_train_result(training_accuracy,training_loss,validation_accuracy,validation_loss, batch_size, learning_rate, epochs, image_size):\n",
        "  \n",
        "  plot_list = []\n",
        "  plot_list.append(training_accuracy)\n",
        "  plot_list.append(validation_accuracy)\n",
        "  plot_list.append(training_loss)\n",
        "  plot_list.append(validation_loss)\n",
        "\n",
        "  title_names = [\"Training_accuracy\", \"Validation_accuracy\",\"Training_loss\",\"Validation_loss\"]\n",
        "\n",
        "  fig = plt.figure(figsize=(12,12))\n",
        "  \n",
        "  for i in range(len(plot_list)):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    # plt.tight_layout()\n",
        "    plt.title(title_names[i],fontweight=\"bold\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    if i < 2:\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "    else:\n",
        "      plt.ylabel(\"Loss\")\n",
        "\n",
        "    \n",
        "    plt.plot(plot_list[i])\n",
        "  fig.suptitle(\"\\n Batch_Size:{}, Learning_Rate:{}, Epochs:{}, Image_Size:{}\\n\".format\n",
        "                (batch_size, learning_rate, epochs, image_size), fontsize=14, fontweight=\"bold\")\n",
        "  \n",
        "  plt.savefig(\"./train_result.png\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3eUx7FX5Kfs"
      },
      "source": [
        "# Performing Predicition on Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggp4PgKKYFa6"
      },
      "source": [
        "def perform_pred(model, test, device, batch_size, data_size, test_data_size):\n",
        "\n",
        "  true_labels = []\n",
        "  predicted_labels = []\n",
        "\n",
        "  examples = enumerate(test)\n",
        "  batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "  example_data, example_targets = example_data.to(device), example_targets.to(device)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\n",
        "    example_data = example_data.view(-1, data_size)\n",
        "    \n",
        "    net_out = model(example_data)\n",
        "\n",
        "  example_data = example_data.cpu().reshape(batch_size,1,test_data_size,test_data_size)\n",
        "\n",
        "  fig = plt.figure()\n",
        "\n",
        "  for i in range(6):\n",
        "\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  \n",
        "    true_label = example_targets[i].item()\n",
        "    true_labels.append(true_label)\n",
        "  \n",
        "    predicted_label = net_out.data.max(1, keepdim=True)[1][i].item()\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "    plt.title(\"Ground-Truth: {}\\n Prediction: {}\".format(true_label, predicted_label ),\n",
        "              fontweight=\"bold\")\n",
        "  \n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "  plt.savefig(\"./prediction.png\")\n",
        "\n",
        "\n",
        "  \n",
        "  return true_labels, predicted_labels"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVNs3aQo5UBD"
      },
      "source": [
        "# Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMLjjXBXfa3"
      },
      "source": [
        "def test_model(model,test_data, device,loss_func, batch_size, data_size, test_data_size):\n",
        "\n",
        "# this code cell calculates accuracy of test data on the trained model.\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  target_list = []\n",
        "  pred_list = []\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_data:\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          data, target = data.to(device), target.to(device)\n",
        "\n",
        "          data = data.view(-1, data_size)\n",
        "          net_out = model(data)\n",
        "          # sum up batch loss\n",
        "          test_loss += loss_func(net_out, target).item()\n",
        "\n",
        "          pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
        "          \n",
        "          \n",
        "          correct += pred.eq(target.data).sum()\n",
        "\n",
        "          # cm = confusion_matrix(target.cpu(),pred.cpu())\n",
        "          target_list.extend( list(target.cpu()) )\n",
        "          pred_list.extend( list(pred.cpu()) )\n",
        "      test_loss /= len(test_data.dataset)\n",
        "      validation_accuracy = correct/len(test_data.dataset)\n",
        "      print('\\nTest Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "              test_loss, correct, len(test_data.dataset),\n",
        "              100. * correct / len(test_data.dataset)))\n",
        "      \n",
        "      target, prediction = perform_pred(model,test_data, device, batch_size, data_size, test_data_size)\n",
        "\n",
        "  return target, prediction, pred_list, target_list\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXirUb1r5ZWH"
      },
      "source": [
        "# Calculating and Plotting F1_Score and Confusion_Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AyxV1i2Xrf-"
      },
      "source": [
        "def calculate_plot_cm_f1(pred_list, target_list):\n",
        "  \n",
        "  cm = confusion_matrix(pred_list,target_list)\n",
        "  f1_scr = f1_score(pred_list, target_list, average='weighted')\n",
        "  print(\"F1-Score : \",f1_scr)\n",
        "  columns = [ str(i) for i in range(10) ]\n",
        "  cm_df = pd.DataFrame(cm,columns,columns)  \n",
        "  fig = plt.figure(figsize=(12,5)) \n",
        "  sns.heatmap(cm_df, annot=True)\n",
        "  plt.ylabel(\"True Labels\") \n",
        "  plt.xlabel(\"Predicted Labels\")\n",
        "  fig.suptitle(\"Confusion_Matrix\", fontweight=\"bold\")\n",
        "  plt.savefig(\"confusion.png\")\n",
        "  plt.show()\n",
        "\n",
        " \n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPsZhabV8qtY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqoWThsd5gIb"
      },
      "source": [
        "# Single Perform_MNIST_NN() Function Calling All Functions()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-wUU4Osm4D9"
      },
      "source": [
        "def Perform_MNIST_NN():\n",
        "\n",
        "  # starting time\n",
        "  start = time.time()\n",
        "\n",
        "  print(start)\n",
        "\n",
        "\n",
        "  test_data_size = 28\n",
        "  train_data_size = 28\n",
        "  batch_size = 32\n",
        "  shuffle = True\n",
        "\n",
        "  # Load Datasets\n",
        "  train,test,validation = loadDataset('/content', test_data_size, train_data_size, batch_size, shuffle )\n",
        "\n",
        "  # Build neural network\n",
        "  number_of_hidden_layers = 2\n",
        "  input_layer_dim = 28*28\n",
        "  neurons_per_layer = [128,64,10]\n",
        "  drop_out = 0.9\n",
        "\n",
        "  model = Net(number_of_hidden_layers, input_layer_dim, neurons_per_layer, drop_out)\n",
        "\n",
        "  # this statement tell our code if there gpu available on our machine or not.\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "  print(model)\n",
        "  print(device)\n",
        "\n",
        "  # Initializing parameters\n",
        "  data_size = 28*28\n",
        "  learning_rate=0.01\n",
        "  epochs= 10\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n",
        "#   optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas = (0.9,0.999))\n",
        "  loss_func = nn.NLLLoss()\n",
        "#   loss_func = nn.CrossEntropyLoss()\n",
        "#   loss_func = nn.KLDivLoss()\n",
        "\n",
        "  #Training the model\n",
        "  training_accuracy, training_loss, validation_accuracy, validation_loss = train_model(data_size, model, train, \n",
        "                                                validation, learning_rate, epochs, optimizer, loss_func, device)\n",
        "\n",
        "  #Plotting the accuracy and loss of train, validation data\n",
        "  plot_train_result(training_accuracy, training_loss, validation_accuracy, validation_loss, batch_size, \n",
        "                    learning_rate, epochs, test_data_size)\n",
        "\n",
        "  #Testing the model and perform predictions\n",
        "  \n",
        "  model.load_state_dict(torch.load(\"./weights.pth\"))\n",
        "  target, prediction, pred_list, target_list = test_model(model,test, device, loss_func, batch_size, data_size, test_data_size)\n",
        "\n",
        "  print(\"True Label: {} \\nPrediction: {}\".format(target, prediction ))\n",
        "\n",
        "  calculate_plot_cm_f1(pred_list, target_list)\n",
        "\n",
        "  end = time.time()\n",
        "  print(f\"Runtime of the program is {end - start}\")\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juon2Xtp5ufS"
      },
      "source": [
        "# Calling Perform_MNIST_NN() Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCnTAVGbUcwU"
      },
      "source": [
        "model = Perform_MNIST_NN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukKdJkSRBd17"
      },
      "source": [
        "# Loading Saved Model and Testing, Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xB7HbkN_NAo"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "test_data_size = 28\n",
        "train_data_size = 28\n",
        "batch_size = 64\n",
        "shuffle = True\n",
        "  # Load Datasets\n",
        "train,test,validation = loadDataset('/content', test_data_size, train_data_size, batch_size, shuffle )\n",
        "\n",
        "model.load_state_dict(torch.load(\"./weights.pth\"))\n",
        "target, prediction, pred_list, target_list = test_model(model,test, device, loss_func)\n",
        "\n",
        "print(\"True Label: {} \\nPrediction: {}\".format(target, prediction ))\n",
        "\n",
        "calculate_plot_cm_f1(pred_list, target_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}